{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Install kaggle and connect colab to dataset"
      ],
      "metadata": {
        "id": "76m3VFCEyMIR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "RLJQ9hwJx2-7",
        "outputId": "293c9514-429d-462c-981f-b01fb83e554a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4650759b-1558-41b7-8de2-2a3702e01274\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4650759b-1558-41b7-8de2-2a3702e01274\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle (1).json\n",
            "mkdir: cannot create directory â€˜/root/.kaggleâ€™: File exists\n"
          ]
        }
      ],
      "source": [
        "!pip install -q kaggle\n",
        "\n",
        "# upload kaggle json\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "# create kaggle folder\n",
        "!mkdir ~/.kaggle\n",
        "\n",
        "# copy json file to kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "# permission for the json to act\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d valentynsichkar/traffic-signs-dataset-in-yolo-format"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVLwgulT7uDW",
        "outputId": "6de4b3e2-41f6-4ad3-975e-449278d8fd3b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "traffic-signs-dataset-in-yolo-format.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unzip the dataset"
      ],
      "metadata": {
        "id": "74gTOMD6yx5F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# unzip the data\n",
        "!unzip traffic-signs-dataset-in-yolo-format.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nn3j-wfFy0f-",
        "outputId": "d37d5a16-739e-46db-9ebf-0bc9dd39b6b9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  traffic-signs-dataset-in-yolo-format.zip\n",
            "replace classes.names? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copy data and labels to train and val folders"
      ],
      "metadata": {
        "id": "GSn_pr3izeoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "def copy_data(folder_name, src_name, dest):\n",
        "  with open(folder_name,\"r\") as f:\n",
        "    for line in f:\n",
        "      splited_line=line.split('/')\n",
        "      src = src_name+splited_line[3]+'/'+splited_line[4]\n",
        "      destination = dest\n",
        "      shutil.copy(src.replace('\\n', ''),destination)\n",
        "\n",
        "def copy_labels(folder_name, src_name, dest):\n",
        "  with open(folder_name,\"r\") as f:\n",
        "    for line in f:\n",
        "      splited_line=line.split('/')\n",
        "      src = src_name+splited_line[3]+'/'+splited_line[4]\n",
        "      destination = dest\n",
        "      shutil.copy(src.replace('\\n', '').replace(\".jpg\",\".txt\"),destination)\n",
        "\n",
        "copy_data(\"train.txt\", \"./ts/\", \"./dataset/train/\")\n",
        "copy_data(\"test.txt\", \"./ts/\", \"./dataset/val/\")\n",
        "copy_labels(\"train.txt\", \"./ts/\", \"./dataset/train/\")\n",
        "copy_labels(\"test.txt\", \"./ts/\", \"./dataset/val/\")"
      ],
      "metadata": {
        "id": "mWfEjKSxzqEu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clone Yolov8"
      ],
      "metadata": {
        "id": "lhwru6yOzI9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/ultralytics\n",
        "!cd ultralytics\n",
        "!pip install -e ultralytics"
      ],
      "metadata": {
        "id": "H1rxJQLxzK6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train yolov8 on custom dataset"
      ],
      "metadata": {
        "id": "ATdNKV4P0QEM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(\"yolov8m.pt\")  # load a pretrained model (recommended for training)\n",
        "\n",
        "# Use the model\n",
        "results = model.train( data=\"/content/ultralytics/ultralytics/datasets/traffic_dataset.yaml\" , epochs=30)  # train the model\n",
        "results = model.val()  # evaluate model performance on the validation set"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6w5ER-rv0meU",
        "outputId": "d10828d6-e60e-4d67-fc3b-37173fe3f80e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.90 ðŸš€ Python-3.10.11 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=/content/ultralytics/ultralytics/datasets/traffic_dataset.yaml, epochs=30, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=/content/ultralytics/runs/detect/train8\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 25.7MB/s]\n",
            "Overriding model.yaml nc=80 with nc=4\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.Conv                  [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.Conv                  [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.C2f                   [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.Conv                  [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.C2f                   [192, 192, 4, True]           \n",
            "  5                  -1  1    664320  ultralytics.nn.modules.Conv                  [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.C2f                   [384, 384, 4, True]           \n",
            "  7                  -1  1   1991808  ultralytics.nn.modules.Conv                  [384, 576, 3, 2]              \n",
            "  8                  -1  2   3985920  ultralytics.nn.modules.C2f                   [576, 576, 2, True]           \n",
            "  9                  -1  1    831168  ultralytics.nn.modules.SPPF                  [576, 576, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 12                  -1  2   1993728  ultralytics.nn.modules.C2f                   [960, 384, 2]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 15                  -1  2    517632  ultralytics.nn.modules.C2f                   [576, 192, 2]                 \n",
            " 16                  -1  1    332160  ultralytics.nn.modules.Conv                  [192, 192, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 18                  -1  2   1846272  ultralytics.nn.modules.C2f                   [576, 384, 2]                 \n",
            " 19                  -1  1   1327872  ultralytics.nn.modules.Conv                  [384, 384, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 21                  -1  2   4207104  ultralytics.nn.modules.C2f                   [960, 576, 2]                 \n",
            " 22        [15, 18, 21]  1   3778012  ultralytics.nn.modules.Detect                [4, [192, 384, 576]]          \n",
            "Model summary: 295 layers, 25858636 parameters, 25858620 gradients, 79.1 GFLOPs\n",
            "\n",
            "Transferred 469/475 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/ultralytics/runs/detect/train8', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to yolov8n.pt...\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.23M/6.23M [00:00<00:00, 123MB/s]\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/dataset/train... 630 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 630/630 [00:00<00:00, 2309.04it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/dataset/train/00340.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/dataset/train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/dataset/val... 111 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:00<00:00, 1230.46it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/dataset/val.cache\n",
            "Plotting labels to /content/ultralytics/runs/detect/train8/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/ultralytics/runs/detect/train8\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/30      6.88G      1.038      5.336     0.8933          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:48<00:00,  1.22s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:08<00:00,  2.02s/it]\n",
            "                   all        111        179      0.876      0.727      0.844      0.667\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/30      6.99G     0.9618     0.9799     0.8398         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:46<00:00,  1.17s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.56it/s]\n",
            "                   all        111        179      0.916       0.88       0.93      0.699\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/30      7.01G      1.049     0.8914     0.8589         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:47<00:00,  1.18s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.55it/s]\n",
            "                   all        111        179      0.959      0.864      0.935      0.668\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/30      7.01G      1.076     0.8706     0.8646         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:52<00:00,  1.30s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.44it/s]\n",
            "                   all        111        179      0.924      0.865      0.927      0.685\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/30      7.01G      1.112     0.7826      0.866         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:48<00:00,  1.21s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.06it/s]\n",
            "                   all        111        179      0.946      0.838      0.933      0.681\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/30         7G      1.032     0.6635     0.8695         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:48<00:00,  1.20s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.49it/s]\n",
            "                   all        111        179      0.903      0.855      0.907      0.673\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/30         7G      1.055     0.6407      0.864          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:53<00:00,  1.34s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.18it/s]\n",
            "                   all        111        179      0.945      0.875      0.938       0.68\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/30         7G      0.957     0.5913     0.8517         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:50<00:00,  1.27s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.49it/s]\n",
            "                   all        111        179      0.949      0.882      0.939      0.739\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/30      6.99G     0.9141     0.5307     0.8483         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:48<00:00,  1.21s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.44it/s]\n",
            "                   all        111        179      0.881      0.858      0.919      0.707\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/30      6.99G     0.8384     0.5009     0.8466          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:47<00:00,  1.20s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.11it/s]\n",
            "                   all        111        179      0.911      0.882      0.928      0.714\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      11/30      7.01G     0.8713     0.5094     0.8232         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:47<00:00,  1.20s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.61it/s]\n",
            "                   all        111        179      0.953        0.9      0.938      0.726\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      12/30      6.99G     0.8378     0.5145     0.8269         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:51<00:00,  1.29s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.52it/s]\n",
            "                   all        111        179      0.969       0.88      0.945       0.74\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      13/30      6.99G      0.832     0.4962     0.8253         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:46<00:00,  1.16s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.00s/it]\n",
            "                   all        111        179      0.951      0.918      0.954      0.767\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      14/30      7.02G      0.773     0.4729      0.829         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:46<00:00,  1.17s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.46it/s]\n",
            "                   all        111        179      0.979      0.854       0.93      0.755\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      15/30      7.03G     0.7691     0.4648     0.8184         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:48<00:00,  1.22s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.58it/s]\n",
            "                   all        111        179      0.921      0.911      0.948      0.731\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      16/30         7G     0.7777     0.4602     0.8112         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:49<00:00,  1.23s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.11s/it]\n",
            "                   all        111        179      0.991       0.89      0.944      0.727\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      17/30         7G     0.7544     0.4703     0.8133         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:48<00:00,  1.21s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.57it/s]\n",
            "                   all        111        179      0.966      0.919      0.972      0.779\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      18/30         7G     0.7214     0.4323     0.8138         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:47<00:00,  1.18s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.58it/s]\n",
            "                   all        111        179      0.972      0.895      0.959      0.782\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      19/30      6.99G     0.7149     0.4148      0.816         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:46<00:00,  1.16s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.01it/s]\n",
            "                   all        111        179      0.947      0.922       0.96      0.797\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      20/30      7.04G     0.6832     0.4124     0.7943         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:46<00:00,  1.15s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.64it/s]\n",
            "                   all        111        179      0.993      0.895      0.966      0.779\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      21/30      7.03G     0.6932     0.4166     0.7957         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:51<00:00,  1.29s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.53it/s]\n",
            "                   all        111        179      0.976      0.894      0.966      0.796\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      22/30         7G     0.6666     0.3974     0.8041         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:49<00:00,  1.25s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.47it/s]\n",
            "                   all        111        179       0.97      0.894      0.969      0.788\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      23/30      7.01G     0.6583     0.3913     0.8102         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:47<00:00,  1.18s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.07s/it]\n",
            "                   all        111        179      0.975      0.913      0.964      0.797\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      24/30      7.03G     0.6447     0.3852      0.799         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:47<00:00,  1.18s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.54it/s]\n",
            "                   all        111        179      0.953      0.914      0.967      0.798\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      25/30      7.01G     0.6245      0.373     0.8005         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:48<00:00,  1.22s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.67it/s]\n",
            "                   all        111        179      0.948      0.922      0.967      0.805\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      26/30      7.01G     0.6266     0.3556     0.7987         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:46<00:00,  1.17s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.04s/it]\n",
            "                   all        111        179      0.988      0.907      0.975      0.796\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      27/30         7G     0.5917     0.3481     0.7966         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:47<00:00,  1.20s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.59it/s]\n",
            "                   all        111        179      0.993      0.892      0.976      0.804\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      28/30      7.01G     0.5981     0.3388     0.8017         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:49<00:00,  1.23s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.58it/s]\n",
            "                   all        111        179      0.968      0.916      0.977      0.817\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      29/30         7G     0.5565     0.3212     0.7943         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:50<00:00,  1.25s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.34it/s]\n",
            "                   all        111        179      0.974      0.916      0.979      0.816\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      30/30      7.01G     0.5505      0.316     0.7918         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:46<00:00,  1.17s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:07<00:00,  1.84s/it]\n",
            "                   all        111        179      0.964      0.936      0.979      0.812\n",
            "\n",
            "30 epochs completed in 0.463 hours.\n",
            "Optimizer stripped from /content/ultralytics/runs/detect/train8/weights/last.pt, 52.0MB\n",
            "Optimizer stripped from /content/ultralytics/runs/detect/train8/weights/best.pt, 52.0MB\n",
            "\n",
            "Validating /content/ultralytics/runs/detect/train8/weights/best.pt...\n",
            "Ultralytics YOLOv8.0.90 ðŸš€ Python-3.10.11 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 218 layers, 25842076 parameters, 0 gradients, 78.7 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.12s/it]\n",
            "                   all        111        179      0.968      0.916      0.977      0.817\n",
            "           prohibitory        111         71      0.962      0.986      0.994      0.829\n",
            "                danger        111         36          1      0.995      0.995      0.882\n",
            "             mandatory        111         23      0.909      0.874      0.976      0.807\n",
            "                 other        111         49          1      0.809      0.944      0.752\n",
            "Speed: 4.0ms preprocess, 6.4ms inference, 0.0ms loss, 5.4ms postprocess per image\n",
            "Results saved to \u001b[1m/content/ultralytics/runs/detect/train8\u001b[0m\n",
            "Ultralytics YOLOv8.0.90 ðŸš€ Python-3.10.11 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 218 layers, 25842076 parameters, 0 gradients, 78.7 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/dataset/val.cache... 111 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.06it/s]\n",
            "                   all        111        179      0.968      0.916      0.977       0.82\n",
            "           prohibitory        111         71      0.962      0.986      0.993      0.826\n",
            "                danger        111         36          1      0.995      0.995       0.89\n",
            "             mandatory        111         23      0.909      0.874      0.976      0.815\n",
            "                 other        111         49          1      0.809      0.944      0.747\n",
            "Speed: 4.3ms preprocess, 14.5ms inference, 0.0ms loss, 4.6ms postprocess per image\n",
            "Results saved to \u001b[1m/content/ultralytics/runs/detect/val\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save weights of yolov8"
      ],
      "metadata": {
        "id": "Q8-_EMZr1Gnp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import shutil\n",
        "\n",
        "shutil.copytree(Path(r'/content/ultralytics/runs'), Path(r'/content/drive/MyDrive/Colab Files/traffic_sign_detector_yolov8'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5FQHv020t6P",
        "outputId": "6f3ac5e5-5195-4dd7-fc54-5fef9e68b941"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/content/drive/MyDrive/Colab Files/traffic_sign_detector_yolov8')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Detect on custom video"
      ],
      "metadata": {
        "id": "-uMLvvLl1X4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(\"/content/ultralytics/runs/detect/train8/weights/best.pt\")\n",
        "results = model(\"/content/traffic-sign-to-test.mp4\", save=True) \n",
        "#!yolo detect predict model=/content/ultralytics/runs/detect/train8/weights/best.pt source=\"/content/traffic-sign-to-test.mp4\" save=True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXgIge_A1f3V",
        "outputId": "5b9886b0-9c41-4c12-a780-51e2ccc4d4c9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "    WARNING âš ï¸ stream/video/webcam/dir predict source will accumulate results in RAM unless `stream=True` is passed,\n",
            "    causing potential out-of-memory errors for large sources or long-running streams/videos.\n",
            "\n",
            "    Usage:\n",
            "        results = model(source=..., stream=True)  # generator of Results objects\n",
            "        for r in results:\n",
            "            boxes = r.boxes  # Boxes object for bbox outputs\n",
            "            masks = r.masks  # Masks object for segment masks outputs\n",
            "            probs = r.probs  # Class probabilities for classification outputs\n",
            "\n",
            "video 1/1 (1/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 26.3ms\n",
            "video 1/1 (2/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 25.3ms\n",
            "video 1/1 (3/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 23.4ms\n",
            "video 1/1 (4/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 23.2ms\n",
            "video 1/1 (5/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 22.8ms\n",
            "video 1/1 (6/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 22.8ms\n",
            "video 1/1 (7/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 20.1ms\n",
            "video 1/1 (8/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 21.3ms\n",
            "video 1/1 (9/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 19.8ms\n",
            "video 1/1 (10/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 19.8ms\n",
            "video 1/1 (11/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 19.8ms\n",
            "video 1/1 (12/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 19.8ms\n",
            "video 1/1 (13/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 19.7ms\n",
            "video 1/1 (14/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 19.5ms\n",
            "video 1/1 (15/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 19.1ms\n",
            "video 1/1 (16/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 18.7ms\n",
            "video 1/1 (17/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 18.7ms\n",
            "video 1/1 (18/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 18.4ms\n",
            "video 1/1 (19/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 18.7ms\n",
            "video 1/1 (20/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 17.1ms\n",
            "video 1/1 (21/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 17.2ms\n",
            "video 1/1 (22/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 17.1ms\n",
            "video 1/1 (23/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 16.7ms\n",
            "video 1/1 (24/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 16.9ms\n",
            "video 1/1 (25/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 16.9ms\n",
            "video 1/1 (26/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 16.1ms\n",
            "video 1/1 (27/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 17.4ms\n",
            "video 1/1 (28/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 15.9ms\n",
            "video 1/1 (29/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 16.2ms\n",
            "video 1/1 (30/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 15.8ms\n",
            "video 1/1 (31/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 15.8ms\n",
            "video 1/1 (32/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 15.8ms\n",
            "video 1/1 (33/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 15.8ms\n",
            "video 1/1 (34/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 15.8ms\n",
            "video 1/1 (35/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 15.9ms\n",
            "video 1/1 (36/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 15.8ms\n",
            "video 1/1 (37/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 16.8ms\n",
            "video 1/1 (38/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 15.8ms\n",
            "video 1/1 (39/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 16.8ms\n",
            "video 1/1 (40/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 15.9ms\n",
            "video 1/1 (41/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 17.5ms\n",
            "video 1/1 (42/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 15.8ms\n",
            "video 1/1 (43/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 15.9ms\n",
            "video 1/1 (44/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 18.8ms\n",
            "video 1/1 (45/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 16.4ms\n",
            "video 1/1 (46/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 16.0ms\n",
            "video 1/1 (47/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 15.8ms\n",
            "video 1/1 (48/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 17.7ms\n",
            "video 1/1 (49/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 16.2ms\n",
            "video 1/1 (50/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 16.6ms\n",
            "video 1/1 (51/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 15.8ms\n",
            "video 1/1 (52/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 15.9ms\n",
            "video 1/1 (53/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 16.3ms\n",
            "video 1/1 (54/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 15.8ms\n",
            "video 1/1 (55/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 18.7ms\n",
            "video 1/1 (56/56) /content/traffic-sign-to-test.mp4: 384x640 2 prohibitorys, 15.8ms\n",
            "Speed: 2.1ms preprocess, 18.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1m/content/ultralytics/runs/detect/predict\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}